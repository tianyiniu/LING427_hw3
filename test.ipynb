{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_81A = pd.read_csv('81A.txt', sep='\\t')\n",
    "df_26A = pd.read_csv(\"26A.txt\", sep=\"\\t\")\n",
    "\n",
    "cols_to_drop = [\"value\", \"latitude\", \"longitude\", \"area\"]\n",
    "\n",
    "df_81A = df_81A.drop(columns=cols_to_drop, axis=1)\n",
    "df_81A = df_81A.rename(columns={\"wals code\": \"wals_code\", \"description\": \"description_81A\"})\n",
    "\n",
    "df_26A = df_26A.drop(columns=cols_to_drop, axis=1)\n",
    "df_26A = df_26A.rename(columns={\"wals code\": \"wals_code\", \"description\": \"description_26A\"})\n",
    "\n",
    "merge_columns = [\"wals_code\", \"name\", \"genus\", \"family\"]\n",
    "df_merged = df_81A.merge(df_26A, on=merge_columns)\n",
    "df_merged = df_merged.replace(\"Strongly suffixing\", \"Suffixing\").replace(\"Weakly suffixing\", \"Suffixing\")\n",
    "df_merged = df_merged.replace(\"Strong prefixing\", \"Prefixing\").replace(\"Weakly prefixing\", \"Prefixing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wals_code', 'name', 'description_81A', 'genus', 'family', 'description_26A']\n",
      "876\n",
      "['Suffixing' 'Equal prefixing and suffixing' 'Little affixation'\n",
      " 'Prefixing']\n"
     ]
    }
   ],
   "source": [
    "cols_merged = [col for col in df_merged.columns]\n",
    "print(cols_merged)\n",
    "print(len(df_merged))\n",
    "print(df_merged.description_26A.unique())\n",
    "\n",
    "# Format accroding to Step 2 chart, write to csv\n",
    "df_step2 = df_merged.drop(columns=[\"wals_code\", \"genus\"])\n",
    "df_step2 = df_step2.rename(columns={\"name\": \"Language\", \"family\": \"Language Family\", \"description_81A\": \"Basic Order\", \"description_26A\": \"Affixes\"})\n",
    "df_step2 = df_step2.reindex(columns=[\"Language\", \"Language Family\", \"Affixes\", \"Basic Order\"])\n",
    "df_step2.to_csv(\"step2_chart\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Suffixing', 'SOV') : 276\n",
      "('Suffixing', 'SVO') : 92\n",
      "('Prefixing', 'SVO') : 81\n",
      "('Little affixation', 'SVO') : 72\n",
      "('Suffixing', 'No dominant order') : 69\n",
      "('Equal prefixing and suffixing', 'SVO') : 43\n",
      "('Equal prefixing and suffixing', 'SOV') : 42\n",
      "('Little affixation', 'SOV') : 29\n",
      "('Equal prefixing and suffixing', 'No dominant order') : 27\n",
      "('Prefixing', 'No dominant order') : 22\n",
      "('Suffixing', 'VSO') : 19\n",
      "('Prefixing', 'SOV') : 19\n",
      "('Equal prefixing and suffixing', 'VSO') : 16\n",
      "('Prefixing', 'VSO') : 15\n",
      "('Little affixation', 'VSO') : 15\n",
      "('Little affixation', 'No dominant order') : 12\n",
      "('Equal prefixing and suffixing', 'VOS') : 7\n",
      "('Prefixing', 'VOS') : 5\n",
      "('Little affixation', 'VOS') : 5\n",
      "('Suffixing', 'VOS') : 3\n",
      "('Suffixing', 'OVS') : 3\n",
      "('Equal prefixing and suffixing', 'OVS') : 3\n",
      "('Little affixation', 'OVS') : 1\n"
     ]
    }
   ],
   "source": [
    "# Produces graph shown on WALS website when tabulating features\n",
    "suffix_word_order = {}\n",
    "\n",
    "for row in df_merged.itertuples():\n",
    "    wals_code, affixing, word_order = row.wals_code, row.description_26A, row.description_81A\n",
    "    if (affixing, word_order) in suffix_word_order:\n",
    "        suffix_word_order[(affixing, word_order)].append(wals_code)\n",
    "    else:\n",
    "        suffix_word_order[(affixing, word_order)] = [wals_code]\n",
    "\n",
    "suffix_word_order = dict(sorted(suffix_word_order.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "for key,vals in suffix_word_order.items():\n",
    "    print(f\"{key} : {len(vals)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOV : 366\n",
      "SVO : 288\n",
      "No dominant order : 130\n",
      "VSO : 65\n",
      "VOS : 20\n",
      "OVS : 7\n"
     ]
    }
   ],
   "source": [
    "word_order_dict = {}\n",
    "for row in df_merged.itertuples():\n",
    "    word_order = row.description_81A\n",
    "    if word_order in word_order_dict:\n",
    "        word_order_dict[word_order] += 1\n",
    "    else:\n",
    "        word_order_dict[word_order] = 1\n",
    "\n",
    "word_order_dict = dict(sorted(word_order_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "for key,vals in word_order_dict.items():\n",
    "    print(f\"{key} : {vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['wals_code', 'name', 'description_81A', 'genus', 'family', 'description_26A']\n",
    "# Now order by language family: \n",
    "# {\"language family\": {\"weak/SOV\": [\"code1\", \"code2\"], \"strong/SOV\": []\"code3\", \"code4\"], ...} , ...}\n",
    "\n",
    "lang_families = {}\n",
    "for row in df_merged.itertuples():\n",
    "    wals_code, affixing, word_order, family = row.wals_code, row.description_26A, row.description_81A, row.family\n",
    "    affixing_word_order = (affixing, word_order)\n",
    "    if family not in lang_families:\n",
    "        lang_families[family] = {affixing_word_order: [wals_code]}\n",
    "        affixing_dict = lang_families[family]\n",
    "        affixing_dict = dict(sorted(affixing_dict.items(), key=lambda dict_tup: len(dict_tup[1]), reverse=True))\n",
    "    else:\n",
    "        affixing_dict = lang_families[family]\n",
    "        if affixing_word_order not in affixing_dict:\n",
    "            affixing_dict[affixing_word_order] = [wals_code]\n",
    "        else:\n",
    "            affixing_dict[affixing_word_order].append(wals_code)\n",
    "        affixing_dict = dict(sorted(affixing_dict.items(), key=lambda dict_tup: len(dict_tup[1]), reverse=True))\n",
    "\n",
    "\n",
    "with open(\"analysis2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for family, affixing_word_order in lang_families.items():\n",
    "        f.write(f\"Language Family: {family}\\n\")\n",
    "        for tup, codes in affixing_word_order.items():\n",
    "            f.write(f\"\\t{tup}: {len(codes)}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVO': 0.329, 'SOV': 0.418, 'No dominant order': 0.148, 'VSO': 0.074, 'VOS': 0.023, 'OVS': 0.008}\n",
      "SVO\n",
      "\tSuffixing : 0.319\n",
      "\tLittle affixation : 0.25\n",
      "\tEqual prefixing and suffixing : 0.149\n",
      "\tPrefixing : 0.281\n",
      "SOV\n",
      "\tEqual prefixing and suffixing : 0.115\n",
      "\tLittle affixation : 0.079\n",
      "\tSuffixing : 0.754\n",
      "\tPrefixing : 0.052\n",
      "No dominant order\n",
      "\tLittle affixation : 0.092\n",
      "\tEqual prefixing and suffixing : 0.208\n",
      "\tSuffixing : 0.531\n",
      "\tPrefixing : 0.169\n",
      "VSO\n",
      "\tSuffixing : 0.292\n",
      "\tPrefixing : 0.231\n",
      "\tEqual prefixing and suffixing : 0.246\n",
      "\tLittle affixation : 0.231\n",
      "VOS\n",
      "\tEqual prefixing and suffixing : 0.35\n",
      "\tSuffixing : 0.15\n",
      "\tPrefixing : 0.25\n",
      "\tLittle affixation : 0.25\n",
      "OVS\n",
      "\tSuffixing : 0.429\n",
      "\tEqual prefixing and suffixing : 0.429\n",
      "\tLittle affixation : 0.143\n",
      "\n",
      "\n",
      "{'Suffixing': 0.527, 'Equal prefixing and suffixing': 0.158, 'Little affixation': 0.153, 'Prefixing': 0.162}\n",
      "Suffixing\n",
      "\tSVO : 0.199\n",
      "\tNo dominant order : 0.149\n",
      "\tSOV : 0.597\n",
      "\tVSO : 0.041\n",
      "\tVOS : 0.006\n",
      "\tOVS : 0.006\n",
      "Equal prefixing and suffixing\n",
      "\tSOV : 0.304\n",
      "\tSVO : 0.312\n",
      "\tNo dominant order : 0.196\n",
      "\tVOS : 0.051\n",
      "\tVSO : 0.116\n",
      "\tOVS : 0.022\n",
      "Little affixation\n",
      "\tSVO : 0.537\n",
      "\tNo dominant order : 0.09\n",
      "\tSOV : 0.216\n",
      "\tVSO : 0.112\n",
      "\tVOS : 0.037\n",
      "\tOVS : 0.007\n",
      "Prefixing\n",
      "\tSVO : 0.57\n",
      "\tNo dominant order : 0.155\n",
      "\tSOV : 0.134\n",
      "\tVSO : 0.106\n",
      "\tVOS : 0.035\n"
     ]
    }
   ],
   "source": [
    "# P(suffixing | SOV) \n",
    "# There are much faster and more efficient ways to calculate this...\n",
    "\n",
    "def format_joint_dict(joint_probs):\n",
    "    for conditional_var in joint_probs:\n",
    "        print(conditional_var)\n",
    "        for resulting_var in joint_probs[conditional_var]:\n",
    "            print(f\"\\t{resulting_var} : {joint_probs[conditional_var][resulting_var]}\")\n",
    "\n",
    "def calculate_affix_given_wordorder(tups):\n",
    "    \"\"\"Input tups: [(code, affix, word order), ...]\"\"\"\n",
    "    # Tabulate joint counts\n",
    "    joint_counts = {}\n",
    "    for code, affix, word_order in tups:\n",
    "        if word_order in joint_counts:\n",
    "            if affix in joint_counts[word_order]: \n",
    "                joint_counts[word_order][affix] += 1\n",
    "            else: \n",
    "                joint_counts[word_order][affix] = 1\n",
    "        else: \n",
    "            joint_counts[word_order]= {affix: 1}\n",
    "        \n",
    "    # Calculate priors\n",
    "    priors = {}\n",
    "    for word_order in joint_counts:\n",
    "        priors[word_order] = round(sum(list(joint_counts[word_order].values())) / len(tups), 3)\n",
    "    print(priors)\n",
    "\n",
    "    # Convert joint_counts into joint probabilities\n",
    "    for word_order in joint_counts:\n",
    "        word_order_counts = sum(list(joint_counts[word_order].values()))\n",
    "        for affix in joint_counts[word_order]:\n",
    "            joint_counts[word_order][affix] = round(joint_counts[word_order][affix] / word_order_counts, 3)\n",
    "    return joint_counts\n",
    "\n",
    "tups = [(row.wals_code, row.description_26A, row.description_81A) for row in df_merged.itertuples()]\n",
    "affix_given_wordorder = calculate_affix_given_wordorder(tups)\n",
    "format_joint_dict(affix_given_wordorder)\n",
    "\n",
    "def calculate_wordorder_given_affix(tups):\n",
    "    \"\"\"Input tups: [(code, affix, word order), ...]\"\"\"\n",
    "    # Tabulate joint counts\n",
    "    joint_counts = {}\n",
    "    for code, affix, word_order in tups:\n",
    "        if affix in joint_counts:\n",
    "            if word_order in joint_counts[affix]: \n",
    "                joint_counts[affix][word_order] += 1\n",
    "            else: \n",
    "                joint_counts[affix][word_order] = 1\n",
    "        else: \n",
    "            joint_counts[affix]= {word_order: 1}\n",
    "    \n",
    "    # Calculate priors\n",
    "    priors = {}\n",
    "    for affix in joint_counts:\n",
    "        priors[affix] = round(sum(list(joint_counts[affix].values())) / len(tups), 3)\n",
    "    print(priors)\n",
    "\n",
    "    # Convert joint_counts into joint probabilities\n",
    "    for affix in joint_counts:\n",
    "        affix_counts = sum(list(joint_counts[affix].values()))\n",
    "        for word_order in joint_counts[affix]:\n",
    "            joint_counts[affix][word_order] = round(joint_counts[affix][word_order] / affix_counts, 3)\n",
    "    return joint_counts\n",
    "\n",
    "print(\"\\n\")\n",
    "wordorder_given_affix = calculate_wordorder_given_affix(tups)\n",
    "format_joint_dict(wordorder_given_affix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Austronesian', 104), ('Niger-Congo', 73), ('Indo-European', 51), ('Sino-Tibetan', 50), ('Afro-Asiatic', 50), ('Trans-New Guinea', 41), ('Pama-Nyungan', 38), ('Eastern Sudanic', 32), ('Uto-Aztecan', 24), ('Altaic', 23), ('Central Sudanic', 19), ('Oto-Manguean', 17), ('Austro-Asiatic', 14), ('Arawakan', 13), ('Uralic', 13), ('Penutian', 12), ('Hokan', 10)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculates conditional probabilities for each language family \n",
    "\n",
    "# How many languages in each langauge family? \n",
    "family_counts = []\n",
    "for family in lang_families:\n",
    "    count = sum([len(langs) for langs in lang_families[family].values()])\n",
    "    family_counts.append((family, count))\n",
    "\n",
    "family_counts =  sorted(family_counts, key=lambda tup: tup[1], reverse=True)\n",
    "#print(family_counts[:30])\n",
    "\n",
    "# Only tabulate statistics for langauge families with more than 15 languages\n",
    "interested_families = [fam for fam in family_counts if fam[1] >= 10]\n",
    "print(interested_families)\n",
    "print(\"\\n\")\n",
    "\n",
    "def format_prob_wordorder_given_affix(tups, probs_threshold=0.0):\n",
    "    \"\"\"Input tups: [(code, affix, word order), ...]\"\"\"\n",
    "    # Tabulate joint counts\n",
    "    joint_counts = {}\n",
    "    for code, affix, word_order in tups:\n",
    "        if affix in joint_counts:\n",
    "            if word_order in joint_counts[affix]: \n",
    "                joint_counts[affix][word_order] += 1\n",
    "            else: \n",
    "                joint_counts[affix][word_order] = 1\n",
    "        else: \n",
    "            joint_counts[affix]= {word_order: 1}\n",
    "    \n",
    "    # Calculate priors\n",
    "    priors = {}\n",
    "    for affix in joint_counts:\n",
    "        priors[affix] = round(sum(list(joint_counts[affix].values())) / len(tups), 3)\n",
    "\n",
    "    # Convert joint_counts into joint probabilities\n",
    "    for affix in joint_counts:\n",
    "        affix_counts = sum(list(joint_counts[affix].values()))\n",
    "        for word_order in joint_counts[affix]:\n",
    "            joint_counts[affix][word_order] = round(joint_counts[affix][word_order] / affix_counts, 3)\n",
    "\n",
    "    # Format joint_counts for writing into output file\n",
    "    lines = []\n",
    "    for affix in joint_counts:\n",
    "        lines.append(\"\\t\"+affix+\"\\n\")\n",
    "        for word_count_probs in joint_counts[affix]:\n",
    "            if joint_counts[affix][word_count_probs] >= probs_threshold:\n",
    "                lines.append(f\"\\t\\t{word_count_probs} : {joint_counts[affix][word_count_probs]}\\n\")\n",
    "            else: \n",
    "                continue\n",
    "\n",
    "    return lines + [\"\\n\"]\n",
    "    \n",
    "lines = []\n",
    "for family_name, family_count in interested_families:\n",
    "    lines += [f\"{family_name}: {family_count} langauges\\n\"]\n",
    "    family_dict = lang_families[family_name]\n",
    "    # Format into list of tuples [(code, affix, word order)]\n",
    "    tups = []\n",
    "    for combination in family_dict:\n",
    "        affix, word_order = combination\n",
    "        codes = family_dict[combination]\n",
    "        for wals_code in codes: \n",
    "            tups.append((wals_code, affix, word_order))\n",
    "    lines += format_prob_wordorder_given_affix(tups, probs_threshold=0.3)\n",
    "\n",
    "with open(\"statistics_per_family2.txt\", \"w\", encoding=\"utf-8\") as f: \n",
    "    f.writelines(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c25f87f1455b9ee457a5fd3eb7c8410c7cc8735896f594ed82ab016906656a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
